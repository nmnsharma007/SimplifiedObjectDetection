{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wJcfjQPhtt0O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Subset,DataLoader, TensorDataset, ConcatDataset\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "id": "wIdPQhV-3z6w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803e56b7-00d7-4145-b08b-54712426feff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = datasets.CIFAR10('/content',train=True,download=True)\n",
        "test_set = datasets.CIFAR10('/content',train=False,download=True)"
      ],
      "metadata": {
        "id": "HlyLoDfix0Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "U3_ZRBDOzz6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inversion and normalization\n",
        "invert = lambda image : 1 - image # function to invert the image\n",
        "normalize = lambda image : image / 255 # function for bringing pixel values in range [0,1]\n",
        "\n",
        "def preprocessing(dataset):\n",
        "    dataset_images = dataset.data\n",
        "    dataset_labels = dataset.targets\n",
        "    dataset_images = normalize(dataset_images)\n",
        "    # dataset_images = invert(dataset_images)\n",
        "    return dataset_images,dataset_labels\n",
        "\n",
        "train_images,train_labels = preprocessing(train_set)\n",
        "test_images,test_labels = preprocessing(test_set)"
      ],
      "metadata": {
        "id": "CbkiZhIzyb_8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the network"
      ],
      "metadata": {
        "id": "qlY5zRh2MT_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self,classes,channels):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(channels,4,5)\n",
        "    self.conv2 = nn.Conv2d(4,6,5)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.fc1 = nn.Linear(6*5*5,128)\n",
        "    self.fc2 = nn.Linear(128,64)\n",
        "    self.fc3 = nn.Linear(64,classes)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    # x = x.unsqueeze(1)\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(x.shape[0],-1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    # x = F.softmax(x,dim=1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "fxZZf9iFMVia"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "wN6Q0Dq4V7lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,trainloader):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "  for e in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for _,(images,labels) in enumerate(trainloader):\n",
        "      images,labels = images.to(device),labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(images)\n",
        "      loss = criterion(output,labels)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "    # else:\n",
        "    #   print(f\"Training loss: {running_loss / len(trainloader)}\")\n",
        "  return model"
      ],
      "metadata": {
        "id": "HRs9DXunV-X3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the model"
      ],
      "metadata": {
        "id": "-20tMrzomwiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model,testloader,classes=2):\n",
        "  correct = np.zeros(classes,dtype=np.float64)\n",
        "  total = np.zeros(classes,dtype=np.float64)\n",
        "  model = model.to(device)\n",
        "  with torch.no_grad():\n",
        "    for images,labels in testloader:\n",
        "      images,labels = images.to(device),labels.to(device)\n",
        "      output = model(images)\n",
        "      pred = torch.argmax(output,dim=1)\n",
        "      for i in range(len(labels)):\n",
        "        correct[labels[i]] += (pred[i] == labels[i])\n",
        "        total[labels[i]] += 1\n",
        "  # print(f\"Accuracy for {classes} classes: {np.sum(correct) / np.sum(total)}\")\n",
        "  return correct[0] / total[0]"
      ],
      "metadata": {
        "id": "k3HVhHkRmx0w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare initial training set"
      ],
      "metadata": {
        "id": "kK1ZrC6jLmo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_subset = {target: np.empty((0,3,32,32),dtype=np.float64) for target in range(num_classes)}\n",
        "\n",
        "\n",
        "for image,label in zip(train_images,train_labels):\n",
        "  image = np.transpose(image,(2,0,1,))\n",
        "  training_subset[label] = np.vstack(([training_subset[label],[image]]))"
      ],
      "metadata": {
        "id": "Gd7GNwHO-R8x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare initial testing set"
      ],
      "metadata": {
        "id": "e7Lzd2p9Bpfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing_subset = {target: np.empty((0,3,32,32),dtype=np.float64) for target in range(num_classes)}\n",
        "\n",
        "\n",
        "for image,label in zip(test_images,test_labels):\n",
        "  image = np.transpose(image,(2,0,1))\n",
        "  testing_subset[label] = np.vstack(([testing_subset[label],[image]]))"
      ],
      "metadata": {
        "id": "KuN_2jfABrTQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_classes):\n",
        "  plt.subplot(2,5,i+1)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(np.transpose(testing_subset[i][100],(1,2,0)))"
      ],
      "metadata": {
        "id": "E7eoFrfEA4wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_subset[2].shape"
      ],
      "metadata": {
        "id": "DU44-UGOGWtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_changes = [[] for x in range(num_classes)]\n",
        "\n",
        "for class_of_interest in range(num_classes):\n",
        "  # class_of_interest = 0\n",
        "  print(f\"Current target class: {class_of_interest}\")\n",
        "\n",
        "  multi_class_train_images = training_subset[class_of_interest].copy()\n",
        "  multi_class_train_labels = np.zeros(multi_class_train_images.shape[0])\n",
        "  multi_class_test_images = testing_subset[class_of_interest].copy()\n",
        "  multi_class_test_labels = np.zeros(multi_class_test_images.shape[0])\n",
        "\n",
        "  for i in range(num_classes):\n",
        "    # prepare the dataset\n",
        "    if i == class_of_interest:\n",
        "      continue\n",
        "    else:\n",
        "      multi_class_train_images = np.vstack((multi_class_train_images,training_subset[i].copy()))\n",
        "      multi_class_train_labels = np.append(multi_class_train_labels,np.ones(training_subset[i].shape[0]))\n",
        "\n",
        "      multi_class_test_images = np.vstack((multi_class_test_images,testing_subset[i]))\n",
        "      multi_class_test_labels = np.append(multi_class_test_labels,np.ones(testing_subset[i].shape[0]))\n",
        "\n",
        "      # print(positive_train_images.shape)\n",
        "      # print(negative_train_images.shape)\n",
        "      train_tensor_x = torch.Tensor(multi_class_train_images)\n",
        "      train_tensor_y = torch.Tensor(multi_class_train_labels)\n",
        "      test_tensor_x = torch.Tensor(multi_class_test_images)\n",
        "      test_tensor_y = torch.Tensor(multi_class_test_labels)\n",
        "      train_dataset = TensorDataset(train_tensor_x,train_tensor_y.to(torch.int64))\n",
        "      test_dataset = TensorDataset(test_tensor_x,test_tensor_y.to(torch.int64))\n",
        "\n",
        "      train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "      test_loader = DataLoader(test_dataset,batch_size=batch_size)\n",
        "      model = NeuralNetwork(2,3)\n",
        "      model = train(model,train_loader)\n",
        "      accuracy = test(model,test_loader)\n",
        "      print(f\"Accuracy of positive class after adding class {i}: {accuracy}\")\n",
        "      accuracy_changes[class_of_interest].append(accuracy)"
      ],
      "metadata": {
        "id": "WuW6tOUdLqf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the accuracy variation for the class of interest\n"
      ],
      "metadata": {
        "id": "zYJyTH9oT_jX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.ylabel(\"Accuracy of target class\")\n",
        "plt.xlabel(\"Number of classes\")\n",
        "for i in range(num_classes):\n",
        "  x = np.linspace(0,10,num=9)\n",
        "  plt.plot(x,accuracy_changes[i],'-s',label = f'Class {i}')\n",
        "# plt.plot(x,accuracy_change_1,'-s',label = 'Class 1')\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy fluctuation\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "USy8cEz8UBil"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}