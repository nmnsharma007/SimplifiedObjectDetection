{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wJcfjQPhtt0O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Subset,DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_classes = 10"
      ],
      "metadata": {
        "id": "wIdPQhV-3z6w"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = datasets.MNIST('/content',train=True,download=True,transform=[transforms.ToTensor()])\n",
        "test_set = datasets.MNIST('/content',train=False,download=True,transform=[transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "HlyLoDfix0Mv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "U3_ZRBDOzz6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inversion and normalization\n",
        "invert = lambda image : 1 - image # function to invert the image\n",
        "normalize = lambda image : image / 255 # function for bringing pixel values in range [0,1]\n",
        "\n",
        "def preprocessing(dataset):\n",
        "    dataset_images = dataset.data.numpy() # convert the dataset into numpy array\n",
        "    dataset_labels = dataset.targets.numpy() # convert the labels into numpy array\n",
        "    dataset_images = invert(dataset_images)\n",
        "    dataset_images = normalize(dataset_images)\n",
        "    return dataset_images,dataset_labels\n",
        "\n",
        "train_images,train_labels = preprocessing(train_set)\n",
        "test_images,test_labels = preprocessing(test_set)"
      ],
      "metadata": {
        "id": "CbkiZhIzyb_8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the data"
      ],
      "metadata": {
        "id": "RgtaFiBp0E5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = TensorDataset(torch.Tensor(train_images),torch.Tensor(train_labels))\n",
        "testing_set = TensorDataset(torch.Tensor(train_images),torch.Tensor(train_labels))\n",
        "\n",
        "subsets = {target: Subset(training_set,[i for i,(X,y) in enumerate(training_set) if y == target]) for _,target in train_set.class_to_idx.items()}\n",
        "loaders = {target: DataLoader(subset) for target,subset in subsets.items()}"
      ],
      "metadata": {
        "id": "pVnDKEdc0HCb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(loaders[3])\n",
        "images,labels = dataiter.next()\n",
        "print(len(loaders[3]))\n",
        "\n",
        "figure = plt.figure()\n",
        "num_of_images = 60\n",
        "for index in range(1,num_of_images+1):\n",
        "  plt.subplot(6,10,index)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(images[index].numpy().squeeze(),cmap='gray_r')"
      ],
      "metadata": {
        "id": "Kxz6-sFu4s7l",
        "outputId": "c844b0c3-112f-4580-8510-284c94edb439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6131\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-fc66f3df0a3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray_r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACoAAAAtCAYAAADYxvnjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAATUlEQVRYhe3OwQnAMAwAsTT77+yu0MdBMUgT6JmZs8H9O/CVaE20JloTrYnWRGuiNdGaaE20JloTrYnWRGuiNdGaaE20JloTrYnW1kRfG+8DV5pqSLIAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}