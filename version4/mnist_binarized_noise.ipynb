{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "IVP7gUnl9Zv0"
      },
      "id": "IVP7gUnl9Zv0"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "import random\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "SuNAsRli9anP"
      },
      "id": "SuNAsRli9anP",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the dataset"
      ],
      "metadata": {
        "id": "rRf3dZDY95WJ"
      },
      "id": "rRf3dZDY95WJ"
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = datasets.MNIST('/content',train=True,download=True)\n",
        "test_set = datasets.MNIST('/content',train=False,download=True)"
      ],
      "metadata": {
        "id": "X11-tMxY97Lk"
      },
      "id": "X11-tMxY97Lk",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inversion and normalization\n",
        "invert = lambda image : 255 - image # function to invert the image\n",
        "\n",
        "def preprocessing(dataset):\n",
        "    dataset_images = dataset.data.numpy() # convert the dataset into numpy array\n",
        "    dataset_labels = dataset.targets.numpy() # convert the labels into numpy array\n",
        "    return dataset_images,dataset_labels\n",
        "\n",
        "train_images,train_labels = preprocessing(train_set)\n",
        "test_images,test_labels = preprocessing(test_set)"
      ],
      "metadata": {
        "id": "PjQKDHPx99-9"
      },
      "id": "PjQKDHPx99-9",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the data"
      ],
      "metadata": {
        "id": "rQvDFNBx-VAZ"
      },
      "id": "rQvDFNBx-VAZ"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_labels(dataset_images,image_type):\n",
        "  labels = np.full(shape=(dataset_images.shape[0]),fill_value=[image_type])\n",
        "  return labels\n",
        "\n",
        "def binarize(dataset_images):\n",
        "  result = np.copy(dataset_images)\n",
        "  for i in range(result.shape[0]):\n",
        "    for j in range(result.shape[1]):\n",
        "      for k in range(result.shape[2]):\n",
        "        if result[i][j][k] > 127:\n",
        "          result[i][j][k] = 1\n",
        "        else:\n",
        "          result[i][j][k] = 0\n",
        "  return result\n",
        "\n",
        "# function for inverting data\n",
        "def get_inverted_data(source_dataset_images,source_dataset_labels,target_dataset,class_num):\n",
        "    image_indices = np.asarray(np.where(source_dataset_labels == class_num))\n",
        "    image_indices = image_indices.flatten()\n",
        "    original_images = invert(source_dataset_images[image_indices]) # get the original images and invert them\n",
        "    target_dataset = np.concatenate((target_dataset,original_images)) # concatenate to our training dataset\n",
        "    return target_dataset\n",
        "\n",
        "# add some data from already available negative data\n",
        "def add_negative_data(source_dataset_images,source_dataset_labels,target_dataset,class_num,amount=2000):\n",
        "  image_indices = np.asarray(np.where(source_dataset_labels != class_num))\n",
        "  image_indices = image_indices.flatten()\n",
        "  np.random.shuffle(image_indices)\n",
        "  image_indices = image_indices[:amount] # take very less amount of negative data\n",
        "  original_images = source_dataset_images[image_indices]\n",
        "  target_dataset = np.concatenate((target_dataset,original_images))\n",
        "  inverted_images = invert(original_images)\n",
        "  target_dataset = np.concatenate((target_dataset,inverted_images))\n",
        "  return target_dataset\n",
        "\n",
        "# function to prepare training data for a given digit\n",
        "def prepare_training_data(dataset_images,dataset_labels,class_num):\n",
        "    indices = np.asarray(np.where(dataset_labels == class_num)) # indices of occurrence of digit as label\n",
        "    indices = indices.flatten()\n",
        "    # get the images for making positive dataset\n",
        "    dataset_images_positive = dataset_images[indices] # images consisting of positive class\n",
        "    dataset_images_positive = binarize(dataset_images_positive) # binarize the images \n",
        "    dataset_labels_positive = generate_labels(dataset_images_positive,0) # generate the class labels\n",
        "    # print(f\"Positive train data shape: {dataset_images_positive.shape}\")\n",
        "    # get the images for making negative dataset\n",
        "    dataset_images_negative = np.empty((0,28,28),dtype=np.float32)\n",
        "    dataset_images_negative = get_inverted_data(dataset_images,dataset_labels,dataset_images_negative,class_num)\n",
        "    dataset_images_negative = add_negative_data(dataset_images,dataset_labels,dataset_images_negative,class_num)\n",
        "    dataset_images_negative = binarize(dataset_images_negative) # binarize the images \n",
        "    dataset_labels_negative = generate_labels(dataset_images_negative,1) # generate the class labels\n",
        "    # print(f\"Negative train data shape: {dataset_images_negative.shape}\")\n",
        "    # concatenate the negative and positive datasets\n",
        "    modified_dataset_images = np.concatenate((dataset_images_positive,dataset_images_negative))\n",
        "    modified_dataset_labels = np.concatenate((dataset_labels_positive,dataset_labels_negative))\n",
        "    return modified_dataset_images,modified_dataset_labels\n",
        "\n",
        "\n",
        "def prepare_testing_data(dataset_images,dataset_labels,class_num):\n",
        "  positive_indices = np.asarray(np.where(dataset_labels == class_num)) # indices of occurrence of digit as label\n",
        "  positive_indices = positive_indices.flatten()\n",
        "  # get the images for making positive dataset\n",
        "  dataset_images_positive = dataset_images[positive_indices] # images consisting of positive class\n",
        "  dataset_images_positive = binarize(dataset_images_positive)\n",
        "  dataset_labels_positive = generate_labels(dataset_images_positive,0) # generate the class labels\n",
        "  # print(f\"Positive test data shape: {dataset_images_positive.shape}\")\n",
        "  # get the images for making negative classes for testing\n",
        "  negative_indices = np.asarray(np.where(((dataset_labels != class_num))))\n",
        "  negative_indices = negative_indices.flatten()\n",
        "  # get the images for making negative dataset\n",
        "  dataset_images_negative = dataset_images[negative_indices]\n",
        "  dataset_images_negative = binarize(dataset_images_negative)\n",
        "  dataset_labels_negative = generate_labels(dataset_images_negative,1)\n",
        "  # print(f\"Negative test data shape: {dataset_images_negative.shape}\")\n",
        "  # concatenate the negative and positive datasets\n",
        "  modified_dataset_images = np.concatenate((dataset_images_positive,dataset_images_negative))\n",
        "  modified_dataset_labels = np.concatenate((dataset_labels_positive,dataset_labels_negative))\n",
        "  return modified_dataset_images,modified_dataset_labels"
      ],
      "metadata": {
        "id": "Y9yNgkwL-WWw"
      },
      "id": "Y9yNgkwL-WWw",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get training and test data"
      ],
      "metadata": {
        "id": "E_vc75lz_TGK"
      },
      "id": "E_vc75lz_TGK"
    },
    {
      "cell_type": "code",
      "source": [
        "class_num = 0\n",
        "trainX,trainy = prepare_training_data(train_images,train_labels,class_num)\n",
        "testX,testy = prepare_testing_data(test_images,test_labels,class_num)"
      ],
      "metadata": {
        "id": "Nkjhda_L_Se6"
      },
      "id": "Nkjhda_L_Se6",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function for creating modified dataset"
      ],
      "metadata": {
        "id": "_T5X8LKHIezR"
      },
      "id": "_T5X8LKHIezR"
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_dataset(X,y,patterns,antipatterns):\n",
        "  p = patterns.shape[0]\n",
        "  ap = antipatterns.shape[0]\n",
        "  modified_train_X = np.empty((0,p+ap),dtype=X.dtype)\n",
        "  modified_train_y = y.copy()\n",
        "  for i in range(X.shape[0]):\n",
        "    image,label = X[i],y[i]\n",
        "    modified_X = np.zeros(p+ap)\n",
        "    for i in (range(p)):\n",
        "      score = np.sum(patterns[i]*image)\n",
        "      modified_X[i] = score\n",
        "    for i in range(ap):\n",
        "      score = np.sum(antipatterns[i]*image)\n",
        "      modified_X[p+i] = score\n",
        "    \n",
        "    modified_train_X = np.vstack((modified_train_X,modified_X))\n",
        "  \n",
        "  return modified_train_X,modified_train_y"
      ],
      "metadata": {
        "id": "IKl1zgJFIgy3"
      },
      "id": "IKl1zgJFIgy3",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find patterns"
      ],
      "metadata": {
        "id": "ckIG-nBO-vAk"
      },
      "id": "ckIG-nBO-vAk"
    },
    {
      "cell_type": "code",
      "source": [
        "patterns = np.empty((0,28,28),dtype=np.float32)\n",
        "antipatterns = np.empty((0,28,28),dtype=np.float32)\n",
        "\n",
        "positive_image_indices = [i for i in range(trainX.shape[0]) if trainy[i] == 0]\n",
        "positive_image = trainX[positive_image_indices[0]]\n",
        "patterns = np.vstack((patterns,[positive_image]))\n",
        "antipatterns = np.vstack((antipatterns,[1-positive_image]))\n",
        "running_trainX,running_trainy = trainX.copy(),trainy.copy()\n",
        "thresh = 0\n",
        "# plt.imshow(antipatterns[-2].squeeze(),cmap='gray')\n",
        "clf_list = []\n",
        "running_trainy[0]\n",
        "num = 0\n",
        "while True:\n",
        "  y_pred = []\n",
        "  tempX = np.empty((0,28,28),dtype=np.float32)\n",
        "  tempy = []\n",
        "  modified_trainX,modified_trainy = modify_dataset(running_trainX,running_trainy,patterns,antipatterns)\n",
        "  print(modified_trainX.shape)\n",
        "  clf = DecisionTreeClassifier(max_depth=1)\n",
        "  clf.fit(modified_trainX,modified_trainy)\n",
        "  clf_list.append((str(num),clf))\n",
        "  num += 1\n",
        "  y_pred = clf.predict(modified_trainX)\n",
        "  for i in range(modified_trainX.shape[0]):\n",
        "    if y_pred[i] != modified_trainy[i]:\n",
        "      tempy.append(modified_trainy[i])\n",
        "      tempX = np.vstack((tempX,[running_trainX[i]]))\n",
        "  print(accuracy_score(modified_trainy,y_pred))\n",
        "\n",
        "  if accuracy_score(modified_trainy,y_pred) == 1:\n",
        "    break\n",
        "  tempy = np.array(tempy)\n",
        "  for i in range(len(y_pred)):\n",
        "    if y_pred[i] == 1 and modified_trainy[i] == 0: # found a false negative\n",
        "      print(\"REACHED\")\n",
        "      patterns = np.vstack((patterns,[running_trainX[i]]))\n",
        "      antipatterns = np.vstack((antipatterns,[1-running_trainX[i]]))\n",
        "      break\n",
        "  \n",
        "  running_trainX,running_trainy = tempX.copy(),tempy.copy()"
      ],
      "metadata": {
        "id": "UDfLxqK_-wb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1133bf3c-1c5d-40bc-ba36-1ab05e4d17c4"
      },
      "id": "UDfLxqK_-wb_",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15846, 2)\n",
            "0.8737851823804115\n",
            "(2000, 2)\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot variations"
      ],
      "metadata": {
        "id": "WqchAoD6FJpG"
      },
      "id": "WqchAoD6FJpG"
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(patterns.shape[0]):\n",
        "  if i+1 > 16:\n",
        "    break\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(patterns[i].squeeze(),cmap='gray')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "xySuT2QqFLWZ",
        "outputId": "024ec0cd-d666-4d6d-db57-62ddff09c849"
      },
      "id": "xySuT2QqFLWZ",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD0AAAA9CAYAAAAeYmHpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAE7ElEQVRoge2az0sbTRjHv7MR3EXwR5RFSFJrhRSkHowmByGQWwnqoc0x13ootE3poRZa/AMERchNgnrIyYMHDyJe1F6KqE0VqUJCBCstplKkwd2ENPu8B+liNElrspvYd/OB55CZyczzzcw88+xkGRHBaHDVdqAa1EQbhZpoo2BI0XXFKhlj//R5RkQsX7khZ7om2igYUnTRQFZJbDYbRFHMKUskEvjy5Yv2gxFRQQNAlbKJiQmSJCnHxsfHy+qzkK6qL++uri4EAgE4nU4IgpBjLpcLgUAA9+7d03bQas40Y4wePXpExVAUhYaHhzWd6artabPZjMnJSXR3d1d87KqINpvN6OzshNfrvRa8ACCTyeD79+9oaGhAY2MjWltb0d7ejkQiAUVRyneg0subMUZzc3N0cnJC2Ww275Le2dmhu3fv0tjYGBER/fjxgz5+/EiiKP47y7u5uRlutxsmkwmMMXR3d+ed4d9kMhmcnJzg58+fAICWlhYQEQYHB/H582dsbGyU51AlZrqvr4/Oz8+LBqzLbG1tkSAI9PLly2t1CwsL/86RxVjeBx7s7u7ixYsXeP/+/bW61dVVBAIB7O3t/bGfm6C7aJ7nIQjCNWeJCLIsY39/H8FgEJubm5AkCZIkQZZlEBF2dnYQDAZxeHioqU+67mme5zEzMwOHw4H6+vqcutPTU/j9fkSjUQDA1NQUwuEwAECWZaTTad380k20zWZDR0cHHA4H7t+/n1MXi8UQjUYRiURwenoKADg+Psbx8fEf+21ubkZ/fz+Ojo6QSCRKc06vQDYxMUGyLJOiKDmBSFEU8vl8xPP8Xx9xi4uL6vez2SxJkkRPnz69PUdWV1cXhoaG4HQ6wfM8gIunpfn5efz69QtEhIODA6RSqZL65zgOgiCgrq501zUX3dPTg6mpKfUzEeHo6AivX7+GLMtaD1cSugaydDqN0dFRbG9v6xqYbopmojmOgyiKaG1tVcuy2SzW19fx6dMnrYbRBM1Ei6KI5eVl3LlzR6sudUMz0SaTCaIooqWlBcBFprW/v4+zszOthtAM3fZ0KBRCMBjUq/uyuDUXg/nweDzw+Xx48OCBWra7u4tQKIT19fWS+72VojmOQ319PVwuF549ewbg4uhLpVJqrl4Ot1K03W7H7OwsrFarWnY1Vy+HWyWa4zjY7XY4nU709vaqDyn5cvWy0Cr3tlgs9PXrVzVHfv78+Y3zdUEQ6MOHD5RKpUrO1S9bxXLvUvF4PHC5XLBareoMRyIRrK2tlZWr50M30YwxMMZ+r5i89Zfx+Xxq0AIuVuDa2hpevXqluW+6iR4ZGYHb7cbo6Cji8XhO3bt37+ByuXLKLh9LsVgMb968wcHBgT7O6bWniYgkSaKHDx+SxWJRzWq10srKSt4LQUVRKJFI0NLSUkl7+KpVZU/zPI9wOIxMJpNTbjab87ZPpVLw+/2IRCKa7uGr6CqaMYa2traibb59+6beY6fTaUSjUW2OpSJUPXpvbGzg8ePHBQOeHmgm+uzsDG/fvsXAwACePHlStO309LR6lx2LxSoqGID2F4PDw8OUTCbp/Pw8ryWTSfJ6vWUHqb+xQrpYsV+5lPfImpqa0NnZWbRNPB5X/6fSEyrwHpnmom8ThURX/fWLalATbRRqoo1C0ej9f8WQM10TbRRqoo2CIUX/B6HPGNmz3BPPAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacking = StackingClassifier(estimators=clf_list,stack_method='predict')\n",
        "modified_testX,modified_testy = modify_dataset(testX,testy,patterns,antipatterns)\n",
        "modified_trainX,modified_trainy = modify_dataset(trainX,trainy,patterns,antipatterns)\n",
        "stacking.fit(modified_trainX,modified_trainy)\n",
        "print(accuracy_score(modified_trainy,clf.predict(modified_trainX)))\n",
        "print(stacking)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpGsaDqD3NbD",
        "outputId": "563d2c58-d24d-4e78-d48c-292f56a53041"
      },
      "id": "hpGsaDqD3NbD",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6262148176195885\n",
            "StackingClassifier(estimators=[('0', DecisionTreeClassifier(max_depth=1)),\n",
            "                               ('1', DecisionTreeClassifier(max_depth=1))],\n",
            "                   stack_method='predict')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the model"
      ],
      "metadata": {
        "id": "gWPJX8qpFXj1"
      },
      "id": "gWPJX8qpFXj1"
    },
    {
      "cell_type": "code",
      "source": [
        "def test(X,y,thresh):\n",
        "  y_pred = []\n",
        "  y_true = []\n",
        "  for i in range(X.shape[0]):\n",
        "    image,label = X[i],y[i]\n",
        "    cnt = 0\n",
        "    for j in range(patterns.shape[0]):\n",
        "      yes_score = np.sum(patterns[j] * image)\n",
        "      no_score = np.sum(antipatterns[j] * image)\n",
        "      cnt += ((yes_score - no_score) >= thresh)\n",
        "    \n",
        "    if cnt >= 1:\n",
        "      y_pred.append(0)\n",
        "    else:\n",
        "      y_pred.append(1)\n",
        "    y_true.append(label)\n",
        "  \n",
        "  return y_true,y_pred"
      ],
      "metadata": {
        "id": "dKK1hVaywCrJ"
      },
      "id": "dKK1hVaywCrJ",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train set results"
      ],
      "metadata": {
        "id": "CaZiFbzkIFZt"
      },
      "id": "CaZiFbzkIFZt"
    },
    {
      "cell_type": "code",
      "source": [
        "# for thresh in range(30,52,2):\n",
        "y_train_true,y_train_pred = test(trainX,trainy,thresh)\n",
        "print(\"#######################################################################\")\n",
        "print(f\"On Training set for threshold: {thresh}\")\n",
        "print(f\"Accuracy of model: {accuracy_score(y_train_true,y_train_pred)}\")\n",
        "print(f\"Precision score: {precision_score(y_train_true,y_train_pred,pos_label=0)}\")\n",
        "print(f\"Recall score: {recall_score(y_train_true,y_train_pred,pos_label=0)}\")\n",
        "print(f\"F1 score: {f1_score(y_train_true,y_train_pred,pos_label=0)}\")\n",
        "tp = 0\n",
        "fp = 0\n",
        "tn = 0\n",
        "fn = 0\n",
        "for i in range(len(y_train_true)):\n",
        "  if y_train_true[i] == 0:\n",
        "    if y_train_pred[i] == 1:\n",
        "      fn += 1\n",
        "    else:\n",
        "      tp += 1\n",
        "  else:\n",
        "    if y_train_pred[i] == 0:\n",
        "      fp += 1\n",
        "    else:\n",
        "      tn += 1\n",
        "\n",
        "print(f\"True positives: {tp}\")\n",
        "print(f\"False positives: {fp}\")\n",
        "print(f\"True negatives: {tn}\")\n",
        "print(f\"False negatives: {fn}\")\n",
        "print(\"#######################################################################\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHqQ-MkcGc6s",
        "outputId": "14f95716-f861-4b10-ed24-bc96ef20cded"
      },
      "id": "OHqQ-MkcGc6s",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#######################################################################\n",
            "On Training set for threshold: 0\n",
            "Accuracy of model: 0.8786444528587656\n",
            "Precision score: 0.9653327128897161\n",
            "Recall score: 0.7004896167482695\n",
            "F1 score: 0.8118579395362489\n",
            "True positives: 4149\n",
            "False positives: 149\n",
            "True negatives: 9774\n",
            "False negatives: 1774\n",
            "#######################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test set results"
      ],
      "metadata": {
        "id": "rCj_P7jiIIYV"
      },
      "id": "rCj_P7jiIIYV"
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_true,y_test_pred = test(testX,testy,thresh)\n",
        "# print(f\"On Testing set for threshold: {thresh}\")\n",
        "print(f\"Accuracy of model: {accuracy_score(y_test_true,y_test_pred)}\")\n",
        "print(f\"Precision score: {precision_score(y_test_true,y_test_pred,pos_label=0)}\")\n",
        "print(f\"Recall score: {recall_score(y_test_true,y_test_pred,pos_label=0)}\")\n",
        "print(f\"F1 score: {f1_score(y_test_true,y_test_pred,pos_label=0)}\")\n",
        "tp = 0\n",
        "fp = 0\n",
        "tn = 0\n",
        "fn = 0\n",
        "for i in range(len(y_test_true)):\n",
        "  if y_test_true[i] == 0:\n",
        "    if y_test_pred[i] == 1:\n",
        "      fn += 1\n",
        "    else:\n",
        "      tp += 1\n",
        "  else:\n",
        "    if y_test_pred[i] == 0:\n",
        "      fp += 1\n",
        "    else:\n",
        "      tn += 1\n",
        "\n",
        "print(f\"True positives: {tp}\")\n",
        "print(f\"False positives: {fp}\")\n",
        "print(f\"True negatives: {tn}\")\n",
        "print(f\"False negatives: {fn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efxTO8_SIEYP",
        "outputId": "306d78d7-b437-4acd-8823-d738132d3cd9"
      },
      "id": "efxTO8_SIEYP",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model: 0.9036\n",
            "Precision score: 0.5057553956834533\n",
            "Recall score: 0.7173469387755103\n",
            "F1 score: 0.5932489451476793\n",
            "True positives: 703\n",
            "False positives: 687\n",
            "True negatives: 8333\n",
            "False negatives: 277\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "MNIST classification.ipynb",
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}