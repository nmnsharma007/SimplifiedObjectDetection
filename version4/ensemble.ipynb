{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "IVP7gUnl9Zv0"
      },
      "id": "IVP7gUnl9Zv0"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "import random\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "SuNAsRli9anP"
      },
      "id": "SuNAsRli9anP",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the dataset"
      ],
      "metadata": {
        "id": "rRf3dZDY95WJ"
      },
      "id": "rRf3dZDY95WJ"
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = datasets.MNIST('/content',train=True,download=True)\n",
        "test_set = datasets.MNIST('/content',train=False,download=True)"
      ],
      "metadata": {
        "id": "X11-tMxY97Lk"
      },
      "id": "X11-tMxY97Lk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inversion and normalization\n",
        "invert = lambda image : 255 - image # function to invert the image\n",
        "\n",
        "def preprocessing(dataset):\n",
        "    dataset_images = dataset.data.numpy() # convert the dataset into numpy array\n",
        "    dataset_labels = dataset.targets.numpy() # convert the labels into numpy array\n",
        "    return dataset_images,dataset_labels\n",
        "\n",
        "train_images,train_labels = preprocessing(train_set)\n",
        "test_images,test_labels = preprocessing(test_set)"
      ],
      "metadata": {
        "id": "PjQKDHPx99-9"
      },
      "id": "PjQKDHPx99-9",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the data"
      ],
      "metadata": {
        "id": "rQvDFNBx-VAZ"
      },
      "id": "rQvDFNBx-VAZ"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_labels(dataset_images,image_type):\n",
        "  labels = np.full(shape=(dataset_images.shape[0]),fill_value=[image_type])\n",
        "  return labels\n",
        "\n",
        "def binarize(dataset_images):\n",
        "  result = np.copy(dataset_images)\n",
        "  for i in range(result.shape[0]):\n",
        "    for j in range(result.shape[1]):\n",
        "      for k in range(result.shape[2]):\n",
        "        if result[i][j][k] > 127:\n",
        "          result[i][j][k] = 1\n",
        "        else:\n",
        "          result[i][j][k] = 0\n",
        "  return result\n",
        "\n",
        "# function for inverting data\n",
        "def get_inverted_data(source_dataset_images,source_dataset_labels,target_dataset,class_num):\n",
        "    image_indices = np.asarray(np.where(source_dataset_labels == class_num))\n",
        "    image_indices = image_indices.flatten()\n",
        "    original_images = invert(source_dataset_images[image_indices]) # get the original images and invert them\n",
        "    target_dataset = np.concatenate((target_dataset,original_images)) # concatenate to our training dataset\n",
        "    return target_dataset\n",
        "\n",
        "# add some data from already available negative data\n",
        "def add_negative_data(source_dataset_images,source_dataset_labels,target_dataset,class_num,amount=2000):\n",
        "  image_indices = np.asarray(np.where(source_dataset_labels != class_num))\n",
        "  image_indices = image_indices.flatten()\n",
        "  np.random.shuffle(image_indices)\n",
        "  image_indices = image_indices[:amount] # take very less amount of negative data\n",
        "  original_images = source_dataset_images[image_indices]\n",
        "  target_dataset = np.concatenate((target_dataset,original_images))\n",
        "  inverted_images = invert(original_images)\n",
        "  target_dataset = np.concatenate((target_dataset,inverted_images))\n",
        "  return target_dataset\n",
        "\n",
        "# function to prepare training data for a given digit\n",
        "def prepare_training_data(dataset_images,dataset_labels,class_num):\n",
        "    indices = np.asarray(np.where(dataset_labels == class_num)) # indices of occurrence of digit as label\n",
        "    indices = indices.flatten()\n",
        "    # get the images for making positive dataset\n",
        "    dataset_images_positive = dataset_images[indices] # images consisting of positive class\n",
        "    dataset_images_positive = binarize(dataset_images_positive) # binarize the images \n",
        "    dataset_labels_positive = generate_labels(dataset_images_positive,0) # generate the class labels\n",
        "    # print(f\"Positive train data shape: {dataset_images_positive.shape}\")\n",
        "    # get the images for making negative dataset\n",
        "    dataset_images_negative = np.empty((0,28,28),dtype=np.float32)\n",
        "    dataset_images_negative = get_inverted_data(dataset_images,dataset_labels,dataset_images_negative,class_num)\n",
        "    # dataset_images_negative = add_negative_data(dataset_images,dataset_labels,dataset_images_negative,class_num)\n",
        "    dataset_images_negative = binarize(dataset_images_negative) # binarize the images \n",
        "    dataset_labels_negative = generate_labels(dataset_images_negative,1) # generate the class labels\n",
        "    # print(f\"Negative train data shape: {dataset_images_negative.shape}\")\n",
        "    # concatenate the negative and positive datasets\n",
        "    modified_dataset_images = np.concatenate((dataset_images_positive,dataset_images_negative))\n",
        "    modified_dataset_labels = np.concatenate((dataset_labels_positive,dataset_labels_negative))\n",
        "    return modified_dataset_images,modified_dataset_labels\n",
        "\n",
        "\n",
        "def prepare_testing_data(dataset_images,dataset_labels,class_num):\n",
        "  positive_indices = np.asarray(np.where(dataset_labels == class_num)) # indices of occurrence of digit as label\n",
        "  positive_indices = positive_indices.flatten()\n",
        "  # get the images for making positive dataset\n",
        "  dataset_images_positive = dataset_images[positive_indices] # images consisting of positive class\n",
        "  dataset_images_positive = binarize(dataset_images_positive)\n",
        "  dataset_labels_positive = generate_labels(dataset_images_positive,0) # generate the class labels\n",
        "  # print(f\"Positive test data shape: {dataset_images_positive.shape}\")\n",
        "  # get the images for making negative classes for testing\n",
        "  negative_indices = np.asarray(np.where(((dataset_labels != class_num))))\n",
        "  negative_indices = negative_indices.flatten()\n",
        "  # get the images for making negative dataset\n",
        "  dataset_images_negative = dataset_images[negative_indices]\n",
        "  dataset_images_negative = binarize(dataset_images_negative)\n",
        "  dataset_labels_negative = generate_labels(dataset_images_negative,1)\n",
        "  # print(f\"Negative test data shape: {dataset_images_negative.shape}\")\n",
        "  # concatenate the negative and positive datasets\n",
        "  modified_dataset_images = np.concatenate((dataset_images_positive,dataset_images_negative))\n",
        "  modified_dataset_labels = np.concatenate((dataset_labels_positive,dataset_labels_negative))\n",
        "  return modified_dataset_images,modified_dataset_labels"
      ],
      "metadata": {
        "id": "Y9yNgkwL-WWw"
      },
      "id": "Y9yNgkwL-WWw",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get training and test data"
      ],
      "metadata": {
        "id": "E_vc75lz_TGK"
      },
      "id": "E_vc75lz_TGK"
    },
    {
      "cell_type": "code",
      "source": [
        "class_num = 0\n",
        "trainX,trainy = prepare_training_data(train_images,train_labels,class_num)\n",
        "testX,testy = prepare_testing_data(test_images,test_labels,class_num)"
      ],
      "metadata": {
        "id": "Nkjhda_L_Se6"
      },
      "id": "Nkjhda_L_Se6",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function for creating modified dataset"
      ],
      "metadata": {
        "id": "_T5X8LKHIezR"
      },
      "id": "_T5X8LKHIezR"
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_dataset(X,y,patterns,antipatterns):\n",
        "  p = patterns.shape[0]\n",
        "  ap = antipatterns.shape[0]\n",
        "  modified_train_X = np.empty((0,p+ap),dtype=X.dtype)\n",
        "  modified_train_y = y.copy()\n",
        "  for i in range(X.shape[0]):\n",
        "    image,label = X[i],y[i]\n",
        "    modified_X = np.zeros(p+ap)\n",
        "    for i in (range(p)):\n",
        "      score = np.sum(patterns[i]*image)\n",
        "      modified_X[i] = score\n",
        "    for i in range(ap):\n",
        "      score = np.sum(antipatterns[i]*image)\n",
        "      modified_X[p+i] = score\n",
        "    \n",
        "    modified_train_X = np.vstack((modified_train_X,modified_X))\n",
        "  \n",
        "  return modified_train_X,modified_train_y"
      ],
      "metadata": {
        "id": "IKl1zgJFIgy3"
      },
      "id": "IKl1zgJFIgy3",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find patterns"
      ],
      "metadata": {
        "id": "ckIG-nBO-vAk"
      },
      "id": "ckIG-nBO-vAk"
    },
    {
      "cell_type": "code",
      "source": [
        "patterns = np.empty((0,28,28),dtype=np.float32)\n",
        "antipatterns = np.empty((0,28,28),dtype=np.float32)\n",
        "\n",
        "positive_image_indices = [i for i in range(trainX.shape[0]) if trainy[i] == 0]\n",
        "positive_image = trainX[positive_image_indices[0]]\n",
        "patterns = np.vstack((patterns,[positive_image]))\n",
        "antipatterns = np.vstack((antipatterns,[1-positive_image]))\n",
        "running_trainX,running_trainy = trainX.copy(),trainy.copy()\n",
        "thresh = 0\n",
        "clf_list = []\n",
        "num = 0\n",
        "while True:\n",
        "  y_pred = []\n",
        "  tempX = np.empty((0,28,28),dtype=np.float32)\n",
        "  tempy = []\n",
        "  modified_trainX,modified_trainy = modify_dataset(running_trainX,running_trainy,patterns,antipatterns)\n",
        "  print(modified_trainX.shape)\n",
        "  clf = DecisionTreeClassifier(max_depth=1)\n",
        "  clf.fit(modified_trainX,modified_trainy)\n",
        "  clf_list.append((str(num),clf))\n",
        "  num += 1\n",
        "  y_pred = clf.predict(modified_trainX)\n",
        "  for i in range(modified_trainX.shape[0]):\n",
        "    if y_pred[i] != modified_trainy[i]:\n",
        "      tempy.append(modified_trainy[i])\n",
        "      tempX = np.vstack((tempX,[running_trainX[i]]))\n",
        "  print(accuracy_score(modified_trainy,y_pred))\n",
        "\n",
        "  if accuracy_score(modified_trainy,y_pred) == 1:\n",
        "    break\n",
        "  tempy = np.array(tempy)\n",
        "  for i in range(len(y_pred)):\n",
        "    if y_pred[i] == 1 and modified_trainy[i] == 0: # found a false negative\n",
        "      print(\"REACHED\")\n",
        "      patterns = np.vstack((patterns,[running_trainX[i]]))\n",
        "      antipatterns = np.vstack((antipatterns,[1-running_trainX[i]]))\n",
        "      break\n",
        "  \n",
        "  running_trainX,running_trainy = tempX.copy(),tempy.copy()"
      ],
      "metadata": {
        "id": "UDfLxqK_-wb_"
      },
      "id": "UDfLxqK_-wb_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot variations"
      ],
      "metadata": {
        "id": "WqchAoD6FJpG"
      },
      "id": "WqchAoD6FJpG"
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(patterns.shape[0]):\n",
        "  if i+1 > 16:\n",
        "    break\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(patterns[i].squeeze(),cmap='gray')\n"
      ],
      "metadata": {
        "id": "xySuT2QqFLWZ"
      },
      "id": "xySuT2QqFLWZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacking = StackingClassifier(estimators=clf_list,stack_method='predict')\n",
        "modified_testX,modified_testy = modify_dataset(testX,testy,patterns,antipatterns)\n",
        "modified_trainX,modified_trainy = modify_dataset(trainX,trainy,patterns,antipatterns)\n",
        "stacking.fit(modified_trainX,modified_trainy)\n",
        "print(accuracy_score(modified_testy,clf.predict(modified_testX)))\n",
        "print(stacking)"
      ],
      "metadata": {
        "id": "hpGsaDqD3NbD"
      },
      "id": "hpGsaDqD3NbD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "MNIST classification.ipynb",
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}